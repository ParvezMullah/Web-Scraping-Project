{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "from collections import OrderedDict\n",
    "from urllib.request import urlopen\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts_links = []\n",
    "top_posts_details = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_links(tag):\n",
    "    post_links = OrderedDict()\n",
    "    url = 'https://medium.com/tag/' + tag\n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    container = soup.find('div', class_ ='js-tagStream')\n",
    "    i = 0\n",
    "    for div in container:\n",
    "        anchor_tag = div.find('a', class_='link link--darken')\n",
    "        post_link = anchor_tag.get('data-action-value')\n",
    "        post_author = (div.find('a', class_='ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken')).text\n",
    "        read = (div.find('span', class_='readingTime')).get('title')\n",
    "        details = div.find('time').text +', ' + str(read)\n",
    "        post_links[post_link] = [post_author, details]\n",
    "        i += 1\n",
    "        if i == 10:\n",
    "            break\n",
    "    return post_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts_links = get_top_links('Blockchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_details(link, author):\n",
    "    details = {}\n",
    "    source = requests.get(link).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    details['author_name'] = author[0]\n",
    "    details['title'] = (soup.find('h1')).text\n",
    "    details['details'] = author[1]\n",
    "    details['blog'] = soup.find('div', class_='section-inner sectionLayout--insetColumn')\n",
    "    (soup.find('h1')).decompose()\n",
    "    tags = soup.findAll('a', class_='link u-baseColor--link')\n",
    "    details['tags'] = [a.text for a in tags]\n",
    "    try:\n",
    "        details['responses'] = (soup.find('button', class_='button button--chromeless u-baseColor--buttonNormal')).text\n",
    "    except:\n",
    "        details['responses'] = 0\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_post_details(top_posts_links):\n",
    "    post_details = OrderedDict()\n",
    "    for link in top_posts_links.keys():\n",
    "        post_details[link] = get_post_details(link, top_posts_links[link])\n",
    "    return post_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts_details = get_all_post_details(top_posts_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in top_posts_details.keys():\n",
    "#     print(top_posts_details[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-122-d0bddd6fc5cc>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-122-d0bddd6fc5cc>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    source = requests.get(url).text\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "container = None\n",
    "\n",
    "def get_top_links(tag):\n",
    "    global top_posts_list\n",
    "    global container\n",
    "\n",
    "    if container is None:\n",
    "        url = 'https://medium.com/tag/' + tag\n",
    "         source = requests.get(url).text\n",
    "#         driver = webdriver.PhantomJS('C:\\\\Users\\\\parvez\\\\Desktop\\\\Scraping Project\\\\mediumscrapingapp\\\\phantomjs')\n",
    "#         # Load Twitter page and click to view all results\n",
    "#         driver.get(url)\n",
    "        soup = BeautifulSoup(source, 'html5lib')\n",
    "        container = soup.findAll('div', class_ ='streamItem streamItem--postPreview js-streamItem')\n",
    "\n",
    "    div = container[0]\n",
    "    container.pop(0)\n",
    "    top_posts = {}\n",
    "    anchor_tag = div.find('a', class_='link link--darken')\n",
    "    post_link = (anchor_tag.get('data-action-value')).split('?source')[0]\n",
    "    post_title = div.find('h3', class_='graf graf--h3 graf-after--figure graf--trailing graf--title')\n",
    "    if post_title == None:\n",
    "        post_title = div.find('h3', class_=\"graf graf--h3 graf-after--figure graf--title\")\n",
    "    nonBreakSpace = u'\\xa0'\n",
    "    if post_title is None:\n",
    "        post_title = \"not found\"\n",
    "    post_title = (post_title.text).replace(nonBreakSpace, ' ')\n",
    "    post_author = (div.find('a', class_='ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken')).text\n",
    "    post_read = (div.find('span', class_='readingTime')).get('title')\n",
    "    post_details = div.find('time').text +', ' + str(post_read)\n",
    "    top_posts['post_link'] = post_link\n",
    "    top_posts['post_title'] = post_title\n",
    "    top_posts['post_author'] = post_author\n",
    "    top_posts['post_details'] = post_details\n",
    "    return top_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"https://medium.com/tag/programming\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-971432e98b44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'programming'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-e34ea1720b9f>\u001b[0m in \u001b[0;36mget_top_links\u001b[1;34m(tag)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'streamItem streamItem--postPreview js-streamItem'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtop_posts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    data = get_top_links('programming')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "from selenium import webdriver\n",
    "\n",
    "def get_post_details(url):\n",
    "    post_detail_view = {}\n",
    "    # source = requests.get(post_link).text\n",
    "    source = url.split('details/')[-1]\n",
    "    #post_title = (source.split('/')[-1]).split('-')[:-1]\n",
    "    #post_detail_view['title'] = ' '.join(post_title)  \n",
    "    post_detail_view['source_url'] = source  \n",
    "    \n",
    "    driver = webdriver.PhantomJS('C:\\\\Users\\\\parvez\\\\Desktop\\\\Scraping Project\\\\mediumscrapingapp\\\\phantomjs')\n",
    "    url = 'https://medium.com/aerum-technologies/wish-id-bought-bitcoin-in-13-af7d9f580853'\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "\n",
    "    post_detail_view['details'] = soup.find('span',attrs={'class':'readingTime'})['title']\n",
    "    post_detail_view['blog'] = (soup.find('div', class_='section-inner sectionLayout--insetColumn')).text\n",
    "    post_detail_view['title'] = (soup.find('h1', class_='graf graf--h3 graf--leading graf--title')).text\n",
    "    # (soup.find('h1')).decompose()\n",
    "    tags = soup.findAll('a', class_='link u-baseColor--link')\n",
    "    post_detail_view['tags'] = [a.text for a in tags]\n",
    "    return post_detail_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_post_details(url):\n",
    "    post_detail_view = {}\n",
    "    # source = requests.get(post_link).text\n",
    "    source = url.split('details/')[-1]\n",
    "    #post_title = (source.split('/')[-1]).split('-')[:-1]\n",
    "    #post_detail_view['title'] = ' '.join(post_title)  \n",
    "    post_detail_view['source_url'] = source  \n",
    "    \n",
    "    driver = webdriver.PhantomJS('C:\\\\Users\\\\parvez\\\\Desktop\\\\Scraping Project\\\\mediumscrapingapp\\\\phantomjs')\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    soup = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "\n",
    "    post_detail_view['details'] = soup.find('span',attrs={'class':'readingTime'})['title']\n",
    "    post_detail_view['blog'] = (soup.find('div', class_='section-inner sectionLayout--insetColumn')).text\n",
    "    post_detail_view['title'] = (soup.find('h1', class_='graf graf--h3 graf--leading graf--title')).text\n",
    "    # (soup.find('h1')).decompose()\n",
    "    tags = soup.findAll('a', class_='link u-baseColor--link')\n",
    "    post_detail_view['tags'] = [a.text for a in tags]\n",
    "    return post_detail_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_url': 'https://medium.com/aerum-technologies/wish-id-bought-bitcoin-in-13-af7d9f580853',\n",
       " 'details': '5 min read',\n",
       " 'blog': 'Wish I’d Bought Bitcoin in\\xa0‘13Every time I meet new crypto people we go through the same little ritual. We ask, and are asked, about our interests in crypto and we discuss what got us interested and when. Everyone says, “I’m not a Bitcoin millionaire.” Then the same thought gets passed around; “I wish I’d gotten in earlier,” we say. It’s a sort of litany. And it’s true, I really do wish I’d bought Bitcoin five, six, or eight years ago. Most of us had heard something about it back then but for whatever reason we didn’t jump in. In my own case I remember thinking “$100, too late to get in. I doubt they’ll go higher.” Of course the assumption is that we wouldn’t have sold out at double or even at 10X but would still have our stake today, at around $6,500 per.That’s the problem, spotting a moonshot while it’s still on the ground. Back then, of course, we didn’t know the value could even go so high. Today we do. If only I could go back and buy at least $100 or $1000 worth, why I’d be….Perhaps some of us bought into ICOs and perhaps some of us even made some money on them. Ahhh, if only we were back in ‘17… but those days are gone too. Right?The problem with ICOs is that they have no fundamental values on which to base estimates of future value. When choosing a stock, even an IPO, you can look at company’s performance, a real product, and maybe even current sales. Underwriters of new stock issues don’t invest in idea level startups. With ICOs though future promise is almost entirely based on hype and faith; spray and pray. We’ve come to accept that to get involved early enough to hope for 10X, 100X, or more we have to go on nothing more than a whitepaper and team description.To make the issue even worse, the vast majority of tokens have absolutely no use other than making money for the startup issuing them. Even if the company holds back a portion of them and locks them up to prevent dumping for a month or year after listing on exchanges, even if the company depends on their future value for their own profits, the tokens are nothing more than holders of market set by arbitrary value. If they drop by 99% the company has the proceeds of the sale in hand and the future token value will have little or no effect on the company’s core business. The startup has gained funding but the token holders will never share in the profits, or have a say in company decisions. Perhaps the token is a medium of exchange in a closed network but that is rarely a necessity\\u200a—\\u200aany other token, and sometimes even fiat, could take their place.The exception to this is AERUM. It’s another reason why I joined the team (another is AERUM’s UX and business focus discussed here). In solving the difficulty of transaction fees for the end user they, perhaps inadvertently, created something almost magic; a basis of fundamental value for their XRM token which also happens to be a Free Money Factory. Like any factory, its own value depends on the value of its output. That is the fundamental value which will give XRM its positive price pressure.The EIP-20 XRM token generates free transactions in the form of Aero tokens (the GAS equivalent in this system). If the holder is a business that needs the transactions, they can apply their Aero to their customers’ transactions. If the holder doesn’t need the transactions, say if the holder is an investor, the Aero can be sold to those who need them, for ETH.Let’s take a look at the investor scenarios a bit closer. Let’s say Ms. CleverInvestor buys XRM. Every day her XRM generate Aero. She doesn’t need the Aero so she sells them and gets ETH. She still holds her XRM, all of them. In effect her XRM are a money factory. XRM is cryptocurrency that literally makes, as in manufactures, money\\u200a—\\u200aEvery single day. She doesn’t need to worry about buying low and selling high; timing the extremely volatile crypto market is simply nothing she needs to concern herself with. She sells low and she sells high\\u200a—\\u200athe next day she sells again.AREUM hasn’t launched its network yet\\u200a—\\u200athat’s coming shortly, mid January of 2019, so obviously there is no demand for Aero yet. Like all business, there is a risk that there may never be. In other words, we are in a stage very like the one everyone wishes they bought into five or eight years ago with Bitcoin. The future is uncertain. The value of XRM is low.The core differences though, are:XRM plays a fundamental role in the Aero tokenomic model, that of generating Aero.The value of transactions, as reflected in the price of Aero vs ETH (or other currencies) will provide a fundamental support floor to the XRM price.Unlike the case of Bitcoin in 2011, we know that crypto can rise by 10X or 1,000X or more.Ultimately, crypto investments are risky. Calling the timing or the token is hard. The cost of making the wrong call is often complete collapse, 100% loss. But the potential in making the right call is unlike anything we’ve seen before. This we know. The value of tokens with no function or fundamental value has soared. How you predict the future value trajectory for a token with the unique properties of core tokenomic function and genuine fundamental value, that is capable of providing a passive income in ETH, in perpetuity, is up to you. The risk, as it was with Bitcoin, is real. The benefits and profits potentially outstrip Bitcoin, even Ethereum.===The AERUM system really is quite cool. Find out more about the scalability, governance, and 100% Ethereum / Solidity compatibility. Or, check out what they already have in BETA.',\n",
       " 'title': 'Wish I’d Bought Bitcoin in\\xa0‘13',\n",
       " 'tags': ['Blockchain', 'Ethereum', 'Aerum', 'Investing', 'ICO']}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:8000/details/https://medium.com/@brideinreverse/why-cooking-for-one-sucks-and-how-to-make-it-less-lonely-a41b72f9a69d'\n",
    "url = 'https://medium.com/aerum-technologies/blockchain-use-cases-more-than-just-potential-9b8b335b14b9'\n",
    "url = 'https://medium.com/aerum-technologies/wish-id-bought-bitcoin-in-13-af7d9f580853'\n",
    "post_detail_view = get_post_details(url)\n",
    "post_detail_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "driver = webdriver.PhantomJS('C:\\\\Users\\\\parvez\\\\Desktop\\\\Scraping Project\\\\mediumscrapingapp\\\\phantomjs')\n",
    "url = 'https://medium.com/aerum-technologies/wish-id-bought-bitcoin-in-13-af7d9f580853'\n",
    "SCROLL_PAUSE_TIME = 1\n",
    "driver.get(url)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(SCROLL_PAUSE_TIME)\n",
    "soup = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "details = soup.find('div', class_='u-flex1 u-paddingLeft15 u-overflowHidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('span',attrs={'class':'readingTime'})['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 min read'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
